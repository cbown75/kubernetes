apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: k8s-monitoring
  namespace: monitoring
  labels:
    app.kubernetes.io/name: k8s-monitoring
    app.kubernetes.io/part-of: monitoring-stack
spec:
  targetNamespace: monitoring
  dependsOn:
    - name: loki
      namespace: monitoring
    - name: prometheus
      namespace: monitoring
  interval: 10m
  timeout: 15m
  chart:
    spec:
      chart: k8s-monitoring
      version: "3.3.1"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
      interval: 12h
  install:
    createNamespace: false
    remediation:
      retries: 3
    replace: true
  upgrade:
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true
  rollback:
    timeout: 10m
    cleanupOnFail: true
  values:
    # Cluster configuration
    cluster:
      name: korriban
      platform: ""
    # External destinations (your existing Prometheus/Loki)
    destinations:
      - name: prometheus-external
        type: prometheus
        url: "http://prometheus-server.monitoring.svc.cluster.local:9090/api/v1/write"
      - name: loki-external
        type: loki
        url: "http://loki.monitoring.svc.cluster.local:3100/loki/api/v1/push"
    # Features to enable
    clusterMetrics:
      enabled: true
      destinations: ["prometheus-external"]
      cost:
        enabled: false
    clusterEvents:
      enabled: true
      destinations: ["loki-external"]
    podLogs:
      enabled: true
      destinations: ["loki-external"]
    # FIXED: Disable node logs for Talos (no journald support)
    nodeLogs:
      enabled: false
    # Disable components you don't need
    alloy-receiver:
      enabled: false
    alloy-profiles:
      enabled: false
    # Metrics collector (StatefulSet for HA)
    alloy-metrics:
      enabled: true
      controller:
        type: statefulset
        replicas: 2
      alloy:
        clustering:
          enabled: true
        # FIXED: Don't add extraPorts for port 12345 - it's already exposed by default
        # The chart automatically exposes:
        # - 12345/TCP: Alloy UI and metrics endpoint
        # - 9999/TCP: Clustering communication
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
    # Logs collector (DaemonSet) - FIXED: Use proper hostPath volumes
    alloy-logs:
      enabled: true
      controller:
        type: daemonset
        # FIXED: Proper volumes configuration at controller level
        volumes:
          extra:
            - name: alloy-log-positions
              hostPath:
                path: /var/lib/alloy-positions
                type: DirectoryOrCreate
        # Tolerations to run on all nodes (like your Promtail)
        tolerations:
          - operator: Exists
            effect: NoSchedule
      alloy:
        # Storage path for log positions
        storagePath: /var/lib/alloy
        # Mount paths for logs and positions
        mounts:
          varlog: true
          dockercontainers: true
          extra:
            - name: alloy-log-positions
              mountPath: /var/lib/alloy
        # Custom log collection configuration (replaces your Promtail config)
        extraConfig: "// Custom pod discovery with filtering (matches your Promtail relabel_configs)\ndiscovery.relabel \"pod_logs_custom\" {\n  targets = discovery.kubernetes.pods.targets\n  \n  // Only collect logs from pods that have containers\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_id\"]\n    regex         = \".+\"\n    action        = \"keep\"\n  }\n  \n  // Extract controller name for app labeling (matches your Promtail)\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_controller_name\"]\n    regex         = \"([0-9a-z-.]+?)(-[0-9a-f]{8,10})?\"\n    target_label  = \"__tmp_controller_name\"\n    action        = \"replace\"\n  }\n  \n  // Set app label from various sources (matches your Promtail)\n  rule {\n    source_labels = [\n      \"__meta_kubernetes_pod_label_app_kubernetes_io_name\",\n      \"__meta_kubernetes_pod_label_app\", \n      \"__tmp_controller_name\",\n      \"__meta_kubernetes_pod_name\"\n    ]\n    regex         = \"(^[0-9a-z-.]+|;[0-9a-z-.]+|;[0-9a-z-.]+|;[0-9a-z-.]+).*\"\n    target_label  = \"app\"\n    action        = \"replace\"\n  }\n  \n  // Set version label\n  rule {\n    source_labels = [\n      \"__meta_kubernetes_pod_label_app_kubernetes_io_version\",\n      \"__meta_kubernetes_pod_label_version\"\n    ]\n    regex         = \"(^[0-9a-z-.]+|;[0-9a-z-.]+).*\"\n    target_label  = \"version\"\n    action        = \"replace\"\n  }\n  \n  // Set namespace\n  rule {\n    source_labels = [\"__meta_kubernetes_namespace\"]\n    target_label  = \"namespace\"\n    action        = \"replace\"\n  }\n  \n  // Set pod name\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_name\"]\n    target_label  = \"pod\"\n    action        = \"replace\"\n  }\n  \n  // Set container name\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_name\"]\n    target_label  = \"container\"\n    action        = \"replace\"\n  }\n  \n  // Construct log path for containerd/Talos (matches your setup)\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_uid\", \"__meta_kubernetes_pod_container_name\"]\n    target_label  = \"__path__\"\n    separator     = \"/\"\n    replacement   = \"/var/log/pods/*${1}/*.log\"\n    action        = \"replace\"\n  }\n  \n  // Drop system namespaces to reduce noise (matches your Promtail)\n  rule {\n    source_labels = [\"__meta_kubernetes_namespace\"]\n    regex         = \"kube-system|flux-system|metallb-system\"\n    action        = \"drop\"\n  }\n}\n\n// Log processing with CRI format parsing (matches your Promtail CRI stage)\nloki.process \"pod_logs_process\" {\n  // Parse CRI format logs (containerd/Talos)\n  stage.cri {}\n  \n  forward_to = [loki.write.loki_external.receiver]\n}\n\n// Kubernetes log source using custom discovery\nloki.source.kubernetes \"pod_logs\" {\n  targets    = discovery.relabel.pod_logs_custom.output\n  forward_to = [loki.process.pod_logs_process.receiver]\n}\n"
        extraEnv:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
        # Security context (required for reading container logs)
        securityContext:
          runAsUser: 0
          runAsGroup: 0
          capabilities:
            add:
              - DAC_READ_SEARCH
            drop:
              - ALL
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
    # Singleton collector for cluster-wide tasks
    alloy-singleton:
      enabled: true
      alloy:
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 512Mi
    # Node Exporter customization (via subchart override)
    prometheus-node-exporter:
      extraArgs:
        - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
        - --collector.netclass.ignored-devices=^(veth.*)$
        - --no-collector.wifi
        - --no-collector.hwmon
    # RBAC configuration
    rbac:
      create: true
    # ServiceAccount configuration
    serviceAccount:
      create: true
      name: k8s-monitoring
    # Prometheus Operator integration
    prometheusOperatorObjects:
      enabled: true
